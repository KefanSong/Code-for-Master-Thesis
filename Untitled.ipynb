{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569a066b-f26c-4009-8e5e-a81ee8cecdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0bb3186-7588-47f6-b012-eb6eb1ad39ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "# import gym\n",
    "import gymnasium as gym\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from data_generator_2groups_4tasks import DataGenerator\n",
    "from models_en import GaussianPolicy, Value, MultiTaskGaussianPolicy,MutilValue\n",
    "from environment import get_threshold\n",
    "from utils import *\n",
    "from collections import deque\n",
    "\n",
    "from big_foot_half_cheetah_v4 import BigFootHalfCheetahEnv\n",
    "from huge_gravity_half_cheetah_v4 import HugeGravityHalfCheetahEnv\n",
    "from ten_fric_half_cheetah_v4 import TenFricHalfCheetahEnv\n",
    "\n",
    "\n",
    "from collections import deque\n",
    "from itertools import combinations\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c7c4274-cdcc-421b-aa80-8cd7d02d1c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Agent:\n",
    "    def __init__(self,env,envname,args,device):\n",
    "        # TO-DO: add the task encoding length to observation dimension.\n",
    "        obs_dim = env.observation_space.shape[0] + 4\n",
    "        act_dim = env.action_space.shape[0]\n",
    "\n",
    "        # Change to multi-gaussian policy. No task_id here.\n",
    "    \n",
    "        # change which to policy\n",
    "        policy = GaussianPolicy(obs_dim, act_dim, args.hidden_size, args.activation, args.logstd)\n",
    "        value_net = Value(obs_dim, args.hidden_size, args.activation)\n",
    "        cvalue_net = Value(obs_dim, args.hidden_size, args.activation)\n",
    "        policy.to(device)\n",
    "        value_net.to(device)\n",
    "        cvalue_net.to(device)\n",
    "        \n",
    "        self.obs_dim = obs_dim\n",
    "        self.act_dim = act_dim\n",
    "        \n",
    "        self.policy = policy\n",
    "        self.value_net = value_net\n",
    "        self.cvalue_net = cvalue_net\n",
    "        \n",
    "        # Initialize optimizer\n",
    "        self.pi_optimizer = torch.optim.Adam(policy.parameters(), args.pi_lr)\n",
    "        self.vf_optimizer = torch.optim.Adam(value_net.parameters(), args.vf_lr)\n",
    "        self.cvf_optimizer = torch.optim.Adam(cvalue_net.parameters(), args.cvf_lr)\n",
    "\n",
    "        lr_lambda = lambda it: max(1.0 - it / args.max_iter_num, 0)\n",
    "        self.pi_scheduler = torch.optim.lr_scheduler.LambdaLR(self.pi_optimizer, lr_lambda=lr_lambda)\n",
    "        self.vf_scheduler = torch.optim.lr_scheduler.LambdaLR(self.vf_optimizer, lr_lambda=lr_lambda)\n",
    "        self.cvf_scheduler = torch.optim.lr_scheduler.LambdaLR(self.cvf_optimizer, lr_lambda=lr_lambda)\n",
    "        \n",
    "        hyperparams = vars(args)\n",
    "        \n",
    "        self.running_stat = RunningStats(clip=5)\n",
    "        self.score_queue = deque(maxlen=100)\n",
    "        self.cscore_queue = deque(maxlen=100)\n",
    "\n",
    "        self.score_queues = [deque(maxlen=100),deque(maxlen=100), deque(maxlen=100), deque(maxlen=100)]\n",
    "        self.logger = Logger(hyperparams, 1)\n",
    "        # envname = envname[env]\n",
    "        self.cost_lim = get_threshold(envname, constraint=args.constraint)\n",
    "        \n",
    "class MultiTaskAgent(Agent):\n",
    "    def __init__(self, env, envname, args, device, num_tasks):\n",
    "        super().__init__(env, envname, args, device)\n",
    "        \n",
    "        # Override the policy with MultiTaskGaussianPolicy\n",
    "        self.policy = MultiTaskGaussianPolicy(self.obs_dim, self.act_dim, num_tasks, \n",
    "                                              args.hidden_size, args.activation, args.logstd)\n",
    "        self.policy.to(device)\n",
    "        \n",
    "        #\n",
    "        self.value_net = MutilValue(self.obs_dim,num_tasks, args.hidden_size, args.activation)\n",
    "        #value_net = Value(obs_dim, args.hidden_size, args.activation)\n",
    "        self.value_net.to(device)\n",
    "        \n",
    "        # Reinitialize the optimizer for the new policy\n",
    "        self.pi_optimizer = torch.optim.Adam(self.policy.parameters(), args.pi_lr)\n",
    "        self.pi_scheduler = torch.optim.lr_scheduler.LambdaLR(self.pi_optimizer, \n",
    "                                                              lr_lambda=lambda it: max(1.0 - it / args.max_iter_num, 0))\n",
    "        #\n",
    "        self.vf_optimizer = torch.optim.Adam(self.value_net.parameters(), args.vf_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "388c19f8-8fa9-41e2-bd6f-b2b843a6aee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--epsilon EPSILON]\n",
      "                             [--rounds-of-update ROUNDS_OF_UPDATE]\n",
      "                             [--env-id ENV_ID] [--constraint CONSTRAINT]\n",
      "                             [--activation ACTIVATION]\n",
      "                             [--hidden_size HIDDEN_SIZE] [--logstd LOGSTD]\n",
      "                             [--gamma GAMMA] [--c-gamma C_GAMMA]\n",
      "                             [--gae-lam GAE_LAM] [--c-gae-lam C_GAE_LAM]\n",
      "                             [--l2-reg L2_REG] [--pi-lr PI_LR] [--vf-lr VF_LR]\n",
      "                             [--cvf-lr CVF_LR] [--lam LAM] [--delta DELTA]\n",
      "                             [--eta ETA] [--nu NU] [--nu_lr NU_LR]\n",
      "                             [--nu_max NU_MAX] [--seed SEED]\n",
      "                             [--max-eps-len MAX_EPS_LEN] [--mb-size MB_SIZE]\n",
      "                             [--batch-size BATCH_SIZE]\n",
      "                             [--num-epochs NUM_EPOCHS]\n",
      "                             [--max-iter-num MAX_ITER_NUM] [--nu-init NU_INIT]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/Kefan/Library/Jupyter/runtime/kernel-68a2f669-be9a-4411-bc0a-81ed2bd3cc82.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Kefan/miniconda3/envs/torch/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3558: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch FOCOPS Implementation')\n",
    "parser.add_argument('--epsilon',type=float, default=1000,\n",
    "                   help='Maximum difference between the return of any two groups (Default: 1000)')\n",
    "parser.add_argument('--rounds-of-update',type=int, default=3,\n",
    "                   help='The number of times policy from each group take turn to update')\n",
    "\n",
    "parser.add_argument('--env-id', default='Humanoid-v3',\n",
    "                    help='Name of Environment (default: Humanoid-v3')\n",
    "parser.add_argument('--constraint', default='velocity',\n",
    "                    help='Constraint setting (default: velocity')\n",
    "parser.add_argument('--activation', default=\"tanh\",\n",
    "                    help='Activation function for policy/critic network (Default: tanh)')\n",
    "parser.add_argument('--hidden_size', type=float, default=(64, 64),\n",
    "                    help='Tuple of size of hidden layers for policy/critic network (Default: (64, 64))')\n",
    "parser.add_argument('--logstd', type=float, default=-0.5,\n",
    "                    help='Log std of Policy (Default: -0.5)')\n",
    "parser.add_argument('--gamma', type=float, default=0.99,\n",
    "                    help='Discount factor for reward (Default: 0.99)')\n",
    "parser.add_argument('--c-gamma', type=float, default=0.99,\n",
    "                    help='Discount factor for cost (Default: 0.99)')\n",
    "parser.add_argument('--gae-lam', type=float, default=0.95,\n",
    "                    help='Lambda value for GAE for reward (Default: 0.95)')\n",
    "parser.add_argument('--c-gae-lam', type=float, default=0.95,\n",
    "                    help='Lambda value for GAE for cost (Default: 0.95)')\n",
    "parser.add_argument('--l2-reg', type=float, default=1e-3,\n",
    "                    help='L2 Regularization Rate (default: 1e-3)')\n",
    "parser.add_argument('--pi-lr', type=float, default=1e-4,\n",
    "                    help='Learning Rate for policy (default: 3e-4)')\n",
    "parser.add_argument('--vf-lr', type=float, default=3e-4,\n",
    "                    help='Learning Rate for value function (default: 3e-4)')\n",
    "parser.add_argument('--cvf-lr', type=float, default=3e-4,\n",
    "                    help='Learning Rate for c-value function (default: 3e-4)')\n",
    "parser.add_argument('--lam', type=float, default=1.5,\n",
    "                    help='Inverse temperature lambda (default: 1.5)')\n",
    "parser.add_argument('--delta', type=float, default=0.02,\n",
    "                    help='KL bound (default: 0.02)')\n",
    "parser.add_argument('--eta', type=float, default=0.02,\n",
    "                    help='KL bound for indicator function (default: 0.02)')\n",
    "# parser.add_argument('--nu', type=float, default=0,\n",
    "#                     help='Cost coefficient (default: 0)')\n",
    "parser.add_argument('--nu', type=float, default=[0, 0],\n",
    "                    help='Cost coefficient (default: 0)')\n",
    "parser.add_argument('--nu_lr', type=float, default=0.01,\n",
    "                    help='Cost coefficient learning rate (default: 0.01)')\n",
    "parser.add_argument('--nu_max', type=float, default=2.0,\n",
    "                    help='Maximum cost coefficient (default: 2.0)')\n",
    "parser.add_argument('--seed', type=int, default=0,\n",
    "                    help='Random Seed (default: 0)')\n",
    "parser.add_argument('--max-eps-len', type=int, default=1000,\n",
    "                    help='Maximum length of episode (default: 1000)')\n",
    "parser.add_argument('--mb-size', type=int, default=64,\n",
    "                    help='Minibatch size per update (default: 64)')\n",
    "parser.add_argument('--batch-size', type=int, default=2048,\n",
    "                    help='Batch Size per Update (default: 2048)')\n",
    "parser.add_argument('--num-epochs', type=int, default=10,\n",
    "                    help='Number of passes through each minibatch per update (default: 10)')\n",
    "parser.add_argument('--max-iter-num', type=int, default=200,\n",
    "                    help='Number of Main Iterations (default: 500)')\n",
    "parser.add_argument(\"--nu-init\", type=float, default=0,\n",
    "                    help=\"the initial nu parameter\")\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b02776dd-5247-4df0-9176-6564051681b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 5 required positional arguments: 'env', 'envname', 'args', 'device', and 'num_tasks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43mMultiTaskAgent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 5 required positional arguments: 'env', 'envname', 'args', 'device', and 'num_tasks'"
     ]
    }
   ],
   "source": [
    "agent = MultiTaskAgent(env, 'hcv4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c29890e5-b151-43f8-9402-7ad618fa4e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('HalfCheetah-v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b813eef7-7666-4d0f-8cc3-b9ff176494d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbce8c8-be62-484d-ba43-a90a8e998fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de1803e-4e91-4c33-9d1c-b3b42c32b6e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79287ead-10b1-4bb7-94b3-dd72ae2e7495",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[2, 1, 3], [1, 2, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cd6bdb-979a-446b-8b25-1f6a19683464",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [2, 1, 3, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f7dd98-062b-447e-beae-bac1bb4067a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3d13be-f026-4327-a08b-64bd8bf8eb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(torch.tensor(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5236cc3d-da8a-4776-a5f8-d9ecfc209d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([2, 2, 3]),\n",
       "indices=tensor([0, 1, 0]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(torch.tensor(a), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f763a021-0482-4f5c-9664-ecd54dd21de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(torch.tensor(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5352b442-a97b-491a-ba8e-77d3fff31e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('x.pkl', 'rb') as f:\n",
    "    q_values = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "403786cf-8c9c-4ae8-8258-92b9483ae288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a19110d-6347-4e71-a23e-f4692bdd1ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.5688, -6.5910, -1.0667,  1.1510,  2.3388, -0.2951, -2.0908,  1.6278,\n",
       "        -1.9939, -0.8018, -0.3756, -2.6624, -0.3271, -0.9380,  0.9938, -0.6569,\n",
       "        -2.5282,  2.6348, -1.9309,  1.1222, -0.4571,  1.1015, -0.0088,  5.1097,\n",
       "        -1.5109,  1.5340, -0.3305, -1.5948,  1.3264,  0.0164, -0.9399, -0.8253,\n",
       "         1.6932, -1.7627,  0.9988, -0.7561, -1.4530, -1.7285,  5.8658, -2.0212,\n",
       "        -0.2736, -1.0093,  7.7411,  2.3708,  0.4603,  0.0329, -0.1991,  0.7409,\n",
       "        -2.3331, -1.1794, -1.3610, -0.5626, -2.8930, -0.2411, -1.8140, -0.4838,\n",
       "         0.5190, -0.8248, -2.4412,  1.6214, -2.6672,  4.1839, -0.7971, -2.3388])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "40ac28b6-a119-4274-b23d-796196035727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-28.6451, -29.3490, -25.4953, -27.8936], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_values[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12b16740-910a-4801-bd18-48e206718237",
   "metadata": {},
   "outputs": [],
   "source": [
    "values, _ = torch.max(q_values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "27d63916-fb0d-4d20-89d2-f4a49f1f916a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-25.4953, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbdb6f9-f99d-4a6b-a0f1-89a90f2ee39b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
